<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Module 5: Multiclass Classification and Metrics - DATASCI 207">
    <title>Module 5: Multiclass Classification and Metrics - DATASCI 207</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="../assets/styles.css">
</head>

<body>
    <header class="nav-header">
        <div class="container">
            <a href="../index.html" class="site-title">DATASCI 207: Applied Machine Learning</a>
        </div>
    </header>

    <main>
        <div class="container">
            <nav class="breadcrumb">
                <a href="../index.html">Home</a>
                <span class="separator">/</span>
                <span>Module 5</span>
            </nav>

            <h1>Module 5: Multiclass Classification and Metrics</h1>

            <p>
                This module extends classification to more than two classes using softmax and
                cross-entropy loss. It also introduces essential evaluation metrics beyond
                accuracy—precision, recall, F1 score, and confusion matrices—and discusses
                the limitations of linear models.
            </p>

            <div class="learning-objectives">
                <h3>Learning Objectives</h3>
                <ul>
                    <li>Define multiclass classification and apply the softmax function.</li>
                    <li>Compute and interpret categorical cross-entropy loss.</li>
                    <li>Evaluate classifiers using precision, recall, F1 score, and confusion matrices.</li>
                    <li>Understand the tradeoffs between precision and recall.</li>
                    <li>Identify limitations of linear models and when more powerful approaches are needed.</li>
                </ul>
            </div>

            <h2>Materials</h2>

            <nav class="module-nav">
                <a href="README.pdf">Module Summary</a>
                <a href="lecture.py">Lecture Code</a>
                <a href="glossary.html">Glossary</a>
                <a href="quiz.html">Knowledge Check</a>
                <a href="readings.html">Additional Readings</a>
                <a href="exercises/">Exercises</a>
                <a href="discussion.html">Discussion Topics</a>
            </nav>

            <h2>Key Concepts</h2>
            <ul>
                <li><strong>Softmax:</strong> Maps multiple values to a probability distribution</li>
                <li><strong>Cross-Entropy Loss:</strong> Measures difference between predicted and true distributions
                </li>
                <li><strong>Precision:</strong> Of those predicted positive, how many are correct?</li>
                <li><strong>Recall:</strong> Of those actually positive, how many did we find?</li>
                <li><strong>Confusion Matrix:</strong> Full picture of classification performance</li>
            </ul>

            <footer>
                <p>
                    <a href="../week_04/index.html">Previous: Module 4</a>
                    <span class="separator">|</span>
                    <a href="../index.html">Course Home</a>
                    <span class="separator">|</span>
                    <a href="../week_06/index.html">Next: Module 6</a>
                </p>
            </footer>
        </div>
    </main>
</body>

</html>