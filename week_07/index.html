<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Module 7: KNN, Decision Trees, and Ensembles - DATASCI 207">
    <title>Module 7: KNN, Decision Trees, and Ensembles - DATASCI 207</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="../assets/styles.css">
</head>

<body>
    <header class="nav-header">
        <div class="container">
            <a href="../index.html" class="site-title">DATASCI 207: Applied Machine Learning</a>
        </div>
    </header>

    <main>
        <div class="container">
            <nav class="breadcrumb">
                <a href="../index.html">Home</a>
                <span class="separator">/</span>
                <span>Module 7</span>
            </nav>

            <h1>Module 7: KNN, Decision Trees, and Ensembles</h1>

            <p>
                This module explores non-parametric and tree-based models. K-Nearest Neighbors uses
                similarity to make predictions. Decision trees partition the feature space using
                interpretable rules. Ensemble methods combine multiple models for better performance.
            </p>

            <div class="learning-objectives">
                <h3>Learning Objectives</h3>
                <ul>
                    <li>Apply k-Nearest Neighbors for classification and understand distance metrics.</li>
                    <li>Explain how decision trees partition data using entropy and information gain.</li>
                    <li>Describe the tradeoffs between model depth and overfitting in trees.</li>
                    <li>Compare ensemble methods: bagging, random forests, and gradient boosting.</li>
                    <li>Implement tree-based models using scikit-learn.</li>
                </ul>
            </div>

            <h2>Materials</h2>

            <nav class="module-nav">
                <a href="README.pdf">Module Summary</a>
                <a href="lecture.py">Lecture Code</a>
                <a href="glossary.html">Glossary</a>
                <a href="quiz.html">Knowledge Check</a>
                <a href="readings.html">Additional Readings</a>
                <a href="exercises/">Exercises</a>
                <a href="discussion.html">Discussion Topics</a>
            </nav>

            <h2>Key Concepts</h2>
            <ul>
                <li><strong>KNN:</strong> Predict based on similar examples</li>
                <li><strong>Decision Trees:</strong> Partition space with learned rules</li>
                <li><strong>Entropy:</strong> Measure of impurity/disorder</li>
                <li><strong>Random Forests:</strong> Ensemble of decorrelated trees</li>
                <li><strong>Gradient Boosting:</strong> Sequential error correction</li>
            </ul>

            <footer>
                <p>
                    <a href="../week_06/index.html">Previous: Module 6</a>
                    <span class="separator">|</span>
                    <a href="../index.html">Course Home</a>
                    <span class="separator">|</span>
                    <a href="../week_08/index.html">Next: Module 8</a>
                </p>
            </footer>
        </div>
    </main>
</body>

</html>