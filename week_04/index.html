<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Module 4: Logistic Regression - DATASCI 207">
    <title>Module 4: Logistic Regression - DATASCI 207</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="../assets/styles.css">
</head>

<body>
    <header class="nav-header">
        <div class="container">
            <a href="../index.html" class="site-title">DATASCI 207: Applied Machine Learning</a>
        </div>
    </header>

    <main>
        <div class="container">
            <nav class="breadcrumb">
                <a href="../index.html">Home</a>
                <span class="separator">/</span>
                <span>Module 4</span>
            </nav>

            <h1>Module 4: Logistic Regression</h1>

            <p>
                This module introduces logistic regression as a machine learning method for binary
                classification. It examines how the sigmoid function transforms linear outputs into
                probabilities, how decision boundaries and thresholds shape predictions, and how
                model parameters are learned using gradient descent with logistic loss.
            </p>

            <div class="learning-objectives">
                <h3>Learning Objectives</h3>
                <ul>
                    <li>Explain logistic regression and identify use cases for classification.</li>
                    <li>Describe the role of the sigmoid function in mapping linear outputs to probabilities.</li>
                    <li>Interpret decision boundaries and apply classification thresholds to make predictions.</li>
                    <li>Compute logistic loss and understand its behavior for different prediction outcomes.</li>
                    <li>Apply gradient descent using the derivative of the sigmoid function to train logistic regression
                        models.</li>
                </ul>
            </div>

            <h2>Materials</h2>

            <nav class="module-nav">
                <a href="README.pdf">Module Summary</a>
                <a href="lecture.py">Lecture Code</a>
                <a href="glossary.html">Glossary</a>
                <a href="quiz.html">Knowledge Check</a>
                <a href="readings.html">Additional Readings</a>
                <a href="exercises/">Exercises</a>
                <a href="discussion.html">Discussion Topics</a>
            </nav>

            <h2>Key Concepts</h2>
            <ul>
                <li><strong>Binary Classification:</strong> Predicting one of two classes</li>
                <li><strong>Sigmoid Function:</strong> Maps any value to range (0, 1)</li>
                <li><strong>Decision Boundary:</strong> Where the model switches predictions</li>
                <li><strong>Classification Threshold:</strong> Probability cutoff for class assignment</li>
                <li><strong>Logistic Loss:</strong> Cross-entropy loss for classification</li>
            </ul>

            <footer>
                <p>
                    <a href="../week_03/index.html">Previous: Module 3</a>
                    <span class="separator">|</span>
                    <a href="../index.html">Course Home</a>
                    <span class="separator">|</span>
                    <a href="../week_05/index.html">Next: Module 5</a>
                </p>
            </footer>
        </div>
    </main>
</body>

</html>